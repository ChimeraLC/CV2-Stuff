import cv2
import numpy as np
import copy
import tensorflow as tf
from TTTSolver import *

def Resize(frame, approx, color = False):
	flattened = approx.ravel()
	if (color):
		x, y, _ = frame.shape
	else:
		x, y = frame.shape
	# Finding counterclockwise orientation
	grid = [[flattened[0], flattened[1]], 
		[flattened[0], flattened[1]],
		[flattened[0], flattened[1]],
		[flattened[0], flattened[1]]]
	# Top left value
	for i in range(int(len(flattened)/2)):
		if (flattened[2*i] + flattened[2*i+1] < grid[0][0] + grid[0][1]):
			grid[0][0] = flattened[2*i]
			grid[0][1] = flattened[2*i+1]
	# Bottom right value
	for i in range(int(len(flattened)/2)):
		if (flattened[2*i] + flattened[2*i+1] > grid[2][0] + grid[2][1]):
			grid[2][0] = flattened[2*i]
			grid[2][1] = flattened[2*i+1]

	# Bottom Left value
	for i in range(int(len(flattened)/2)):
		if (flattened[2*i] - flattened[2*i+1] < grid[1][0] - grid[1][1]):
			grid[1][0] = flattened[2*i]
			grid[1][1] = flattened[2*i+1]

			
	# Top right value
	for i in range(int(len(flattened)/2)):
		if (flattened[2*i] - flattened[2*i+1] > grid[3][0] - grid[3][1]):
			grid[3][0] = flattened[2*i]
			grid[3][1] = flattened[2*i+1]
	
	warpGrid = np.array([[10, 10], [10, y-10], [x-10, y-10], [x-10, 10]], dtype="float32")
	grid = np.array(grid, dtype="float32")

	warpMethod = cv2.getPerspectiveTransform(grid, warpGrid)
	warped = cv2.warpPerspective(frame, warpMethod, (x+10, y+10))
	return warped

# Finds the top left value
def TopLeft(approx):
	flattened = approx.ravel()
	ret = [flattened[0], flattened[1]]
	for i in range(int(len(flattened)/2)):
		if (flattened[2*i] + flattened[2*i+1] < ret[0] + ret[1]):
			ret[0] = flattened[2*i]
			ret[1] = flattened[2*i+1]
	return ret


savedPosition = -1

# Initialize the webcam
cap = cv2.VideoCapture(0)
# Attempts to find the larger tictactoe grid within the image
#def find_grid(frame):

#Load tensorflow model
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(20, 30)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(2)
])
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
model.load_weights('./Checkpoints/TTT_Checkpoint').expect_partial()



found = False
while True:
	# Read each frame from the webcam
	_, frame = cap.read()

	x, y, c = frame.shape

	total_area = x * y

	# Flip the frame vertically
	frame = cv2.flip(frame, 1)
	blur = cv2.blur(frame, (3, 3))
	frame2 = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)
	
	thresh = cv2.adaptiveThreshold(
		   frame2, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 51, 3
	)



	contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
	maxArea = 0

	#cv2.drawContours(frame2, contours, -1, (0,255,0), 3)
	for c in contours:
        # Approximate the contour
		peri = cv2.arcLength(c, True)
		approx = cv2.approxPolyDP(c, 0.01 * peri, True)

		area = cv2.contourArea(c)
        # Check for contours that are quadrilateral and also not too small
		if area > maxArea and area / total_area < 0.9 and len(approx) == 4:
			#cv2.drawContours(frame, [approx], 0, (0, 255, 0), 3)
			warped = Resize(thresh, approx)
			warpedColor = Resize(frame, approx, True)
			maxArea = area

	# fixing broken lines
	kernel = np.ones((3, 3), np.uint8)  # note this is a horizontal kernel
	d_im = cv2.dilate(warped, kernel, iterations=1)
	e_im = cv2.erode(d_im, kernel, iterations=1) 
	warped2 = e_im
	
	# Thicken lines
	inner_contours, _ = cv2.findContours(warped2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
	for i in inner_contours:
		cv2.drawContours(warped2, [i], -1, (0, 0, 0), 10)
	inner_contours, _ = cv2.findContours(warped2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
	# Find contours

	x1, y1 = warped2.shape
	outer = x1*y1
	squares = []
	originals = []
	for i in inner_contours:
		peri = cv2.arcLength(i, True)
		approx = cv2.approxPolyDP(i, 0.02 * peri, True)
		
		inner = cv2.contourArea(approx)
		if (inner/outer > 0.02 and inner/outer < 0.2 and len(approx) < 7):
			# Making sure is a square
			_, _, w,h = cv2.boundingRect(approx)
			if (w/h < 0.5 or h/w < 0.5):
				continue
			cv2.drawContours(warped, [approx], 0, (255, 255, 0), 3)
			cv2.drawContours(warpedColor, [approx], 0, (255, 255, 0), 3)
			# TODO: order the squares
			squares.append(Resize(warped, approx))
			originals.append(approx)

	if (len(squares) == 9):
		savedSquares = squares
		savedOriginals = copy.deepcopy(originals)
		savedOriginals2 = copy.deepcopy(originals)
		saved = warpedColor
		found = True
		shrunk = False

	if found:
		if shrunk == False:
			for i in range(9):
				# First, sort squares to get the right oder
				savedOriginals[i] = TopLeft(savedOriginals[i])
				shrunk = True

		# sorting by rows
		sort = sorted(zip(savedOriginals, savedSquares, savedOriginals2), key=lambda x: x[0][1])
		savedOriginals = [x for x, _, _ in sort]
		savedOriginals2 = [x for _, _, x in sort]
		savedSquares = [x for _, x, _ in sort]

		# sort the columns
		for i in range(3):
			sort = sorted(zip(savedOriginals[i*3:i*3+3], savedSquares[i*3:i*3+3],
		     savedOriginals2[i*3:i*3+3]), key=lambda x: x[0][0])
			savedOriginals[i*3:i*3+3] = [x for x, _ ,_ in sort]
			savedOriginals2[i*3:i*3+3] = [x for _, _ ,x in sort]
			savedSquares[i*3:i*3+3] = [x for _, x, _ in sort]

		# Shrink images for use with model				
		alteredSquares = []
		# Alter images
		for i in range(9):
			res = cv2.resize(savedSquares[i], dsize=(33, 25), interpolation=cv2.INTER_CUBIC)
			alteredSquares.append(cv2.getRectSubPix(res, (30, 20), (17, 13)))

		# Reading grid
		predictions = model.predict(np.array(alteredSquares), verbose=0)
		predictions = [np.argmax(x) for x in predictions]
		# Checking for any white squares
		for i in range(9):
			if (np.mean(alteredSquares[i]) > 250):
				predictions[i] = 2

		position = Solve(predictions)
		if (position != -1):
			savedPosition = position

		# Drawing prediction
		if savedPosition != -1:
			currentContour = savedOriginals2[savedPosition]
			M = cv2.moments(currentContour)
			if M['m00'] != 0:
				cx = int(M['m10']/M['m00'])
				cy = int(M['m01']/M['m00'])
				cv2.putText(warped2, str(savedPosition), (cx - 20, cy - 20),
						cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
	
		cv2.imshow("Output3" ,warped2)
	
	# TODO: draw the found contours onto the affected file
			
	# Show the final output
	cv2.imshow("Output", thresh) 
	if cv2.waitKey(1) == ord('q'):
		break

# release the webcam and destroy all active windows
cap.release()

cv2.destroyAllWindows()

